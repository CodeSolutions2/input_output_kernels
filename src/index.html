<!DOCTYPE html>
<html>
<head></head>
<body>

<button id="run_selection_ODE" onclick="run_selection_ODE()">run_selection_ODE</button>
<br>
<button id="run_selection_NN" onclick="run_selection_NN()">run_selection_NN</button>

<div id="output">

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>

<script>


var epochs = 200;
var lr = 0.001;



async function run_selection_ODE() {
   
  // Train an ODE.
  await train_model0(lr, epochs);
}


async function run_selection_NN() {
  
  // Train a Neural Network.
  await train_model1(lr, epochs);
}


async function train_model0(lr, epochs) {

  var x = tf.variable(tf.scalar(0.05)); //initial value 
  const optimizer = tf.train.adam(lr);  //gradient descent algorithm 
  for (var i=0; i<epochs; i++) { 
    var y = optimizer.minimize(() => model0(x), true, [x]);
    
    if (i%20 == 1){ 
      document.getElementById("output").innerHTML += "y: "+y+", x: "+x+"<br>";
    }
  }

}



function model0(x) {
  const f1 = x.pow(tf.scalar(2, 'int32'))
  return f1
}



async function train_model1(lr, epoch) {

  var xs_js = [[1.2, 9], [1.4, 1.2], 
               [0.9, 10], [1.5, 9.5], 
               [0.6, 10.6], [0.5, 10.3],
               [1.5, 0.5], [1.2, 1.9]];
  var rows = xs_js.length;
  var cols = xs_js.at(0).length;
  var xs = tf.variable(tf.tensor(xs_js, [rows, cols]));
  document.getElementById("output").innerHTML += "xs.shape: "+xs.shape+"<br>";

  var ys_js = [[0], [1], 
               [0], [1], 
               [0], [0],
               [1], [1]];
  var ys_actual = tf.tensor(ys_js);

  // Define how one calculates the weights of the graph, or [how one descends the loss functions].
  const optimizer = tf.train.adam(lr);
  // OR
  // const optimizer = tf.train.sgd(lr); 

  // Initialize the weights and bias.
  var [w0, b0, w1, b1] = await initialize_weights(rows, cols);
  document.getElementById("output").innerHTML += "w0.shape: "+w0.shape+"<br>";
  document.getElementById("output").innerHTML += "b0.shape: "+b0.shape+"<br>";
  document.getElementById("output").innerHTML += "w1.shape: "+w1.shape+"<br>";
  document.getElementById("output").innerHTML += "b1.shape: "+b1.shape+"<br>";

  // Call train_step
  for (var i=0; i<epochs; i++) { 
    var loss = optimizer.minimize(() => train_step1(xs, ys_actual, w0, b0, w1, b1), true, [w0, b0, w1, b1]);
    
    if (i%20 == 1){ 
      document.getElementById("output").innerHTML += "loss: "+loss+"<br>";
    }
  }

} // end of train_model1



function train_step1(xs, ys_actual, w0, b0, w1, b1) {

  // [0] Calculate ys_pred for inputting all of xs.
  const ys_pred = model1(xs, w0, b0, w1, b1);
  document.getElementById("output").innerHTML += "ys_pred: "+ys_pred+"<br>";
  
  // [1] Calculate the error/loss between ys_actual and ys_pred.
  var loss = loss_fn(ys_pred, ys_actual);
  document.getElementById("output").innerHTML += "loss in train_step1: "+loss+"<br>";

  return loss;
}



function loss_fn(ys_pred, ys_actual) {
  
  const loss = tf.losses.sigmoidCrossEntropy(ys_actual, ys_pred);
  // loss.data().then(l => console.log('Loss', l));
  return loss;
}


async function initialize_weights(rows, cols) {
  // The weights and biases for the two dense layers.
  var layer_dims = [16, 8];

  var w0 = tf.variable(tf.randomNormal([layer_dims.at(0), rows]));
  var b0 = tf.variable(tf.randomNormal([layer_dims.at(0), cols]));
  var w1 = tf.variable(tf.randomNormal([layer_dims.at(1), rows]));
  var b1 = tf.variable(tf.randomNormal([layer_dims.at(1), cols]));

  return [w0, b0, w1, b1];
}


function model1(xs, w0, b0, w1, b1) {

  var layer0 = xs.matMul(w0).add(b0);
  document.getElementById("output").innerHTML += "layer0: "+layer0+"<br>";
  
  // return .relu().matMul(w1).add(b1);
  return layer0;
}

</script>
</body>
</html>
